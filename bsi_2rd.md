## BSI二次评审

上次评审的主要问题：1）多个bitmap进行merge/split开销 2）index空间占用，膨胀率？

其中问题（1）通过与计算层协商做了一些限制，即计算层不使用过滤返回的bitmap做额外的计算，从而可以将BSI的计算过程下推到segment级别。所以剩下的问题就是评估在segment级别BSI的表现如何，也顺带回答问题（2）。

下面做了一组实验，场景是针对不同行数的segment，用10个segment来模拟一个结点级别的计算。分别通过 1）单线程扫描所有segment的某一列统计结果 2）把所有segment使用BSI进行过滤、聚合的结果进行统计，对比两种方式的耗时，并观察索引的空间占用。

* **实验一：耗时对比**（单位为行数、微秒）

![](./line0120.png)

![](./data0120.png)

* **实验二：空间对比**（单位为行数、字节数）

![](./line1.png)

![](./data1.png)

需要注意的是，这里的数据文件指**仅包含一列**的segment文件，因为压缩友好所以可能导致数据文件偏小。考虑以下schema：[int8, int16, int32, int64]，根据这个schema生成的160万行segment为6,307,138 bytes，为这四列生成的BSI总大小为4,235,084 bytes，约占数据文件体积的67%。

* 结论
  * BSI本身适用的场景比较窄，只有极个别不带GROUP BY的简单查询能用上。对于用户来讲实用性比较低，benchmark上目前也难以对竞品形成足够大的优势。
  * 根据以上测试结果，BSI只有在巨大数据量的场景下（i.e. 一亿行）性能才会有数量级的优势，并且数据量较小时空间膨胀比较严重。
  * 针对第二点，一个可行的方案是增大BSI的粒度，做到node级别。但是这会带来比较多的额外工作量，需要依赖其他模块的相关功能。
  * 综上，考虑到BSI在现阶段的实际意义并不大，直接投入去做的话工作量较大，效果可能也无法达到预期，建议暂时先降低BSI的优先级，待依赖的功能完成且有足够人力时可考虑继续研发。

